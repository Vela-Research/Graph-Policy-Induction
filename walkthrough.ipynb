{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0a3206",
   "metadata": {},
   "source": [
    "# **Graph-Policy-Induction Walkthrough**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcc5ce8",
   "metadata": {},
   "source": [
    "This notebook goes through all of the code for the graph-based feature extraction step by step. This code has been modularised into various scripts and a config file where parameters can be adjusted according to the user (see README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9710fbe",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "\n",
    "Warning: Torch geometric can be hard to install so this particular package may take some time. It is best to install from conda-forge using mamba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66019dc",
   "metadata": {},
   "source": [
    "### Standard Packages\n",
    "- os\n",
    "- json\n",
    "- pathlib (Path)\n",
    "- collections (defaultdict)\n",
    "- dataclasses\n",
    "- enum\n",
    "- typing\n",
    "- warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c47257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2c8b92",
   "metadata": {},
   "source": [
    "### External Packages (covered in requirements.txt):\n",
    "\n",
    "- torch ‚Üí covered by torch>=2.0.0,<2.3.0\n",
    "    - torch.nn\n",
    "    - torch.nn.functional (F)\n",
    "- torch_geometric ‚Üí covered by torch-geometric>=2.4.0\n",
    "    - torch_geometric.data.HeteroData\n",
    "    - torch_geometric.nn (SAGEConv, HeteroConv, Linear, GATConv)\n",
    "- pandas ‚Üí covered by pandas>=2.0.0\n",
    "- numpy ‚Üí covered by numpy>=1.24.0,<2.0.0\n",
    "- sklearn ‚Üí covered by scikit-learn>=1.3.0\n",
    "    - sklearn.model_selection.train_test_split\n",
    "    - sklearn.ensemble (RandomForestClassifier, GradientBoostingClassifier)\n",
    "    - sklearn.metrics (precision_score, recall_score, roc_auc_score, fbeta_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f751d7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imm/grte4643/miniconda3/envs/vela_clean/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import fbeta_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import GATConv, HeteroConv, Linear, SAGEConv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7d44f9",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f978c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf42928e",
   "metadata": {},
   "source": [
    "# Data Processing \n",
    "\n",
    "The data processing code loads and combines the private and public datasets from Vela. \n",
    "\n",
    "It parses various dtypes stored as json inside the csv columns, computes feature statistics, extracts baseline features for education/job and finally filters these features for redundnacy using jaccard similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc53d03c",
   "metadata": {},
   "source": [
    "### Combining Data\n",
    "\n",
    "Checks for any duplicate founders (which there weren't any), adding a success tag and adding source tracking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3560f8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "LOADING & COMBINING DATASETS\n",
      "==================================================\n",
      "Public:  4500 founders (405 successful)\n",
      "Private: 4500 founders (405 successful)\n",
      "\n",
      "Combined: 9000 founders\n",
      "  Success rate: 9.00%\n",
      "  Successful: 810\n",
      "==================================================\n",
      "                              founder_uuid  success  \\\n",
      "0     33159ebb-97ff-43fe-a80e-31fdcf467065        1   \n",
      "1     33a7bba0-2ef6-415b-b73c-3dc994b8a86e        1   \n",
      "2     0fe9fcdf-eb06-4e2c-88d8-04468b427298        1   \n",
      "3     4f5620d4-9db8-4cfc-a1f5-2fd917472865        1   \n",
      "4     c347a753-2280-48f8-9a78-8bcff30dd0ac        1   \n",
      "...                                    ...      ...   \n",
      "8995  4524d31b-af37-4980-9fe6-491b8d55eb88        0   \n",
      "8996  4afdd8f1-b76d-4a7c-ab5d-e26eb5a9ed91        0   \n",
      "8997  7d1dcfd0-4383-43f8-be23-660dc0c214e8        0   \n",
      "8998  1844623e-c893-45a6-aa60-cc91b4a4bfb2        0   \n",
      "8999  1ada8d2a-8875-483e-aad2-be7b6ef5c232        0   \n",
      "\n",
      "                                               industry  \\\n",
      "0          Technology, Information & Internet Platforms   \n",
      "1                             Entertainment & Live Arts   \n",
      "2     Industrial & Agricultural Machinery Manufacturing   \n",
      "3                   Research Services & Market Analysis   \n",
      "4               Biotechnology & Nanotechnology Research   \n",
      "...                                                 ...   \n",
      "8995            Biotechnology & Nanotechnology Research   \n",
      "8996                                 Financial Services   \n",
      "8997            Biotechnology & Nanotechnology Research   \n",
      "8998                               Software Development   \n",
      "8999                    IT Services & Digital Solutions   \n",
      "\n",
      "                                                   ipos  \\\n",
      "0                                                   NaN   \n",
      "1                                                   NaN   \n",
      "2                                                   NaN   \n",
      "3                                                   NaN   \n",
      "4     [{'amount_raised_usd': '50M - 150M', 'valuatio...   \n",
      "...                                                 ...   \n",
      "8995                                                NaN   \n",
      "8996                                                NaN   \n",
      "8997                                                NaN   \n",
      "8998                                                NaN   \n",
      "8999                                                NaN   \n",
      "\n",
      "                                           acquisitions  \\\n",
      "0                                                   NaN   \n",
      "1                                                   NaN   \n",
      "2                                                   NaN   \n",
      "3                                                   NaN   \n",
      "4     [{'price_usd': 'Undisclosed', 'acquired_by_wel...   \n",
      "...                                                 ...   \n",
      "8995                                                NaN   \n",
      "8996                                                NaN   \n",
      "8997                                                NaN   \n",
      "8998                                                NaN   \n",
      "8999                                                NaN   \n",
      "\n",
      "                                        educations_json  \\\n",
      "0     [\\n  {\\n    \"degree\": \"BA\",\\n    \"field\": \"Com...   \n",
      "1     [\\n  {\\n    \"degree\": \"\",\\n    \"field\": \"\",\\n ...   \n",
      "2                                                   NaN   \n",
      "3     [\\n  {\\n    \"degree\": \"PhD\",\\n    \"field\": \"Ph...   \n",
      "4     [\\n  {\\n    \"degree\": \"\",\\n    \"field\": \"\",\\n ...   \n",
      "...                                                 ...   \n",
      "8995  [\\n  {\\n    \"degree\": \"BS\",\\n    \"field\": \"Com...   \n",
      "8996  [\\n  {\\n    \"degree\": \"BA\",\\n    \"field\": \"Pri...   \n",
      "8997  [\\n  {\\n    \"degree\": \"PhD\",\\n    \"field\": \"Sy...   \n",
      "8998  [\\n  {\\n    \"degree\": \"PhD\",\\n    \"field\": \"\",...   \n",
      "8999  [\\n  {\\n    \"degree\": \"BS\",\\n    \"field\": \"Soc...   \n",
      "\n",
      "                                              jobs_json  \\\n",
      "0     [\\n  {\\n    \"role\": \"CTO\",\\n    \"company_size\"...   \n",
      "1     [\\n  {\\n    \"role\": \"Board of Directors, VP\",\\...   \n",
      "2     [\\n  {\\n    \"role\": \"Security Expert\",\\n    \"c...   \n",
      "3     [\\n  {\\n    \"role\": \"Professor\",\\n    \"company...   \n",
      "4     [\\n  {\\n    \"role\": \"Executive Chairman\",\\n   ...   \n",
      "...                                                 ...   \n",
      "8995  [\\n  {\\n    \"role\": \"VP (Engineering)\",\\n    \"...   \n",
      "8996  [\\n  {\\n    \"role\": \"Founder, Board Member\",\\n...   \n",
      "8997  [\\n  {\\n    \"role\": \"Bioinformatics Team Lead\"...   \n",
      "8998  [\\n  {\\n    \"role\": \"Head of Public Policy\",\\n...   \n",
      "8999  [\\n  {\\n    \"role\": \"Global Accounts Manager (...   \n",
      "\n",
      "                                       anonymised_prose   source  \n",
      "0     This founder leads a startup in the Technology...   public  \n",
      "1     This founder leads a startup in the Entertainm...   public  \n",
      "2     This founder leads a startup in the Industrial...   public  \n",
      "3     This founder leads a startup in the Research S...   public  \n",
      "4     This founder leads a startup in the Biotechnol...   public  \n",
      "...                                                 ...      ...  \n",
      "8995  This founder leads a startup in the Biotechnol...  private  \n",
      "8996  This founder leads a startup in the Financial ...  private  \n",
      "8997  This founder leads a startup in the Biotechnol...  private  \n",
      "8998  This founder leads a startup in the Software D...  private  \n",
      "8999  This founder leads a startup in the IT Service...  private  \n",
      "\n",
      "[9000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "def load_and_combine_datasets(\n",
    "    public_path: str = '/home/imm/grte4643/Documents/Vela/Inputs/vcbench_final_public.csv',\n",
    "    private_path: str = '/home/imm/grte4643/Documents/Vela/Inputs/vcbench_final_private.csv'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and combine public + private datasets.\n",
    "    \n",
    "    Returns:\n",
    "        Combined DataFrame with 'source' column\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"LOADING & COMBINING DATASETS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    df_public = pd.read_csv(public_path)\n",
    "    df_private = pd.read_csv(private_path)\n",
    "    \n",
    "    print(f\"Public:  {len(df_public)} founders ({df_public['success'].sum()} successful)\")\n",
    "    print(f\"Private: {len(df_private)} founders ({df_private['success'].sum()} successful)\")\n",
    "    \n",
    "    public_uuids = set(df_public['founder_uuid'])\n",
    "    private_uuids = set(df_private['founder_uuid'])\n",
    "    overlap = len(public_uuids & private_uuids)\n",
    "    \n",
    "    if overlap > 0:\n",
    "        print(f\"\\n WARNING: {overlap} founders in both datasets - removing duplicates\")\n",
    "        df_private = df_private[~df_private['founder_uuid'].isin(public_uuids)]\n",
    "    \n",
    "    df_public['source'] = 'public'\n",
    "    df_private['source'] = 'private'\n",
    "    df_combined = pd.concat([df_public, df_private], ignore_index=True)\n",
    "    \n",
    "    print(f\"\\nCombined: {len(df_combined)} founders\")\n",
    "    print(f\"  Success rate: {df_combined['success'].mean()*100:.2f}%\")\n",
    "    print(f\"  Successful: {df_combined['success'].sum()}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    return df_combined\n",
    "\n",
    "df = load_and_combine_datasets()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40a195c",
   "metadata": {},
   "source": [
    "### JSON Parsing Utility Functions\n",
    "\n",
    "These are the JSON parsing helper functions. \n",
    "- Parse json converts JSON strings to Python dictionaries (used by feature extraction)\n",
    "- Parse qs rank standardises mass unviersity ranking strings to clean integers\n",
    "- Parse duration converts job duration strings to numeric years using midpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73e80bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_column(json_str: Any) -> List[Dict]:\n",
    "    \"\"\"Safely parse JSON columns.\"\"\"\n",
    "    if pd.isna(json_str):\n",
    "        return []\n",
    "    try:\n",
    "        return json.loads(json_str)\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return []\n",
    "\n",
    "\n",
    "def parse_qs_rank(qs_value: Any) -> int:\n",
    "    \"\"\"Parse QS ranking handling '200+', '101-150', etc.\"\"\"\n",
    "    if pd.isna(qs_value) or qs_value == '':\n",
    "        return 999\n",
    "    \n",
    "    qs_str = str(qs_value).strip()\n",
    "    \n",
    "    if '+' in qs_str:\n",
    "        try:\n",
    "            return int(qs_str.replace('+', ''))\n",
    "        except ValueError:\n",
    "            return 999\n",
    "    \n",
    "    if '-' in qs_str:\n",
    "        try:\n",
    "            return int(qs_str.split('-')[0])\n",
    "        except ValueError:\n",
    "            return 999\n",
    "    \n",
    "    try:\n",
    "        return int(float(qs_str))\n",
    "    except ValueError:\n",
    "        return 999\n",
    "\n",
    "\n",
    "def parse_duration(duration_str: Any) -> float:\n",
    "    \"\"\"Parse job duration strings to years.\"\"\"\n",
    "    if pd.isna(duration_str) or duration_str == '':\n",
    "        return 0.0\n",
    "    \n",
    "    d = str(duration_str).lower()\n",
    "    \n",
    "    if '10+' in d or '>10' in d:\n",
    "        return 12.0\n",
    "    elif '6-9' in d or '6-10' in d:\n",
    "        return 7.5\n",
    "    elif '4-5' in d or '4-6' in d:\n",
    "        return 4.5\n",
    "    elif '2-3' in d or '2-4' in d:\n",
    "        return 2.5\n",
    "    elif '<2' in d or '0-2' in d or '1-2' in d:\n",
    "        return 1.0\n",
    "    elif '<1' in d or '0-1' in d:\n",
    "        return 0.5\n",
    "    else:\n",
    "        try:\n",
    "            return float(''.join(c for c in d if c.isdigit() or c == '.'))\n",
    "        except ValueError:\n",
    "            return 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a391950",
   "metadata": {},
   "source": [
    "### Education and Job Feature Extraction\n",
    "\n",
    "For each founder, we turn the JSON data into numerical features accross job and education\n",
    "- Education extraction parses the educations_json column and extracts or analyses: \n",
    "    - Degress and their number (PhD, MBA, Masters)\n",
    "    - Fields (STEM, Business)\n",
    "    - University Ranking (QS)\n",
    "\n",
    "- Job extraction parses their jobs_json column and extracts or analyses: \n",
    "    - Seniority: CxO, VP, director role\n",
    "    - Role types: tech, product, business\n",
    "    - Company size: big vs startup\n",
    "    - Experience: yrs worked in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b49668e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting education features...\n",
      "  ‚úì Extracted 13 education features\n",
      "Extracting job features...\n",
      "  ‚úì Extracted 17 job features\n",
      "      edu_num_degrees  edu_highest_degree_score  edu_best_qs_rank  \\\n",
      "0                   1                         0               1.0   \n",
      "1                   0                         0               6.0   \n",
      "2                   0                         0               NaN   \n",
      "3                   2                         4               6.0   \n",
      "4                   1                         0               4.0   \n",
      "...               ...                       ...               ...   \n",
      "8995                1                         0             163.0   \n",
      "8996                1                         0             200.0   \n",
      "8997                4                         4              48.0   \n",
      "8998                3                         4               3.0   \n",
      "8999                1                         0             200.0   \n",
      "\n",
      "      edu_is_top10_school  edu_is_top50_school  edu_is_top100_school  \\\n",
      "0                       1                    1                     1   \n",
      "1                       1                    1                     1   \n",
      "2                       0                    0                     0   \n",
      "3                       1                    1                     1   \n",
      "4                       1                    1                     1   \n",
      "...                   ...                  ...                   ...   \n",
      "8995                    0                    0                     0   \n",
      "8996                    0                    0                     0   \n",
      "8997                    0                    1                     1   \n",
      "8998                    1                    1                     1   \n",
      "8999                    0                    0                     0   \n",
      "\n",
      "      edu_has_phd  edu_has_mba  edu_has_masters  edu_has_advanced_degree  ...  \\\n",
      "0               0            0                0                        0  ...   \n",
      "1               0            0                0                        0  ...   \n",
      "2               0            0                0                        0  ...   \n",
      "3               1            0                0                        1  ...   \n",
      "4               0            0                0                        0  ...   \n",
      "...           ...          ...              ...                      ...  ...   \n",
      "8995            0            0                0                        0  ...   \n",
      "8996            0            0                0                        0  ...   \n",
      "8997            1            0                0                        1  ...   \n",
      "8998            1            0                1                        1  ...   \n",
      "8999            0            0                0                        0  ...   \n",
      "\n",
      "      job_total_experience_years  job_num_industries  job_has_cxo_experience  \\\n",
      "0                            7.5                   4                       1   \n",
      "1                           14.0                   2                       1   \n",
      "2                            7.5                   1                       0   \n",
      "3                           26.5                   2                       1   \n",
      "4                           14.0                   1                       1   \n",
      "...                          ...                 ...                     ...   \n",
      "8995                        12.0                   2                       0   \n",
      "8996                        41.0                   4                       1   \n",
      "8997                         9.5                   2                       1   \n",
      "8998                         5.5                   3                       1   \n",
      "8999                        25.0                   6                       1   \n",
      "\n",
      "      job_has_prior_founder_exp  job_has_big_company_exp  job_has_startup_exp  \\\n",
      "0                             0                        0                    0   \n",
      "1                             0                        0                    1   \n",
      "2                             0                        1                    1   \n",
      "3                             1                        1                    0   \n",
      "4                             0                        0                    0   \n",
      "...                         ...                      ...                  ...   \n",
      "8995                          0                        1                    1   \n",
      "8996                          1                        0                    1   \n",
      "8997                          0                        1                    1   \n",
      "8998                          0                        1                    1   \n",
      "8999                          0                        1                    1   \n",
      "\n",
      "      job_is_technical  job_is_technical_senior  job_is_repeat_founder  \\\n",
      "0                    1                        1                      0   \n",
      "1                    0                        0                      0   \n",
      "2                    0                        0                      0   \n",
      "3                    0                        0                      0   \n",
      "4                    0                        0                      0   \n",
      "...                ...                      ...                    ...   \n",
      "8995                 1                        1                      0   \n",
      "8996                 0                        0                      1   \n",
      "8997                 0                        0                      0   \n",
      "8998                 0                        0                      0   \n",
      "8999                 0                        0                      0   \n",
      "\n",
      "      job_big_company_then_startup  \n",
      "0                                0  \n",
      "1                                0  \n",
      "2                                1  \n",
      "3                                0  \n",
      "4                                0  \n",
      "...                            ...  \n",
      "8995                             1  \n",
      "8996                             0  \n",
      "8997                             1  \n",
      "8998                             1  \n",
      "8999                             1  \n",
      "\n",
      "[9000 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "def extract_education_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Extract education-related features.\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    print(\"Extracting education features...\")\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        edu_data = parse_json_column(row.get('educations_json', '[]'))\n",
    "        \n",
    "        degrees = [e.get('degree', '') for e in edu_data if e.get('degree')]\n",
    "        fields = [e.get('field', '') for e in edu_data if e.get('field')]\n",
    "        qs_ranks = [parse_qs_rank(e.get('qs_ranking')) for e in edu_data]\n",
    "        qs_ranks = [r for r in qs_ranks if r < 999]\n",
    "        \n",
    "        # degree analysis\n",
    "        degree_score, has_phd, has_mba, has_masters = 0, 0, 0, 0\n",
    "        for d in degrees:\n",
    "            d_lower = d.lower()\n",
    "            if 'phd' in d_lower or 'doctor' in d_lower:\n",
    "                degree_score = max(degree_score, 4)\n",
    "                has_phd = 1\n",
    "            elif 'mba' in d_lower:\n",
    "                degree_score = max(degree_score, 3)\n",
    "                has_mba = 1\n",
    "            elif 'master' in d_lower or 'msc' in d_lower:\n",
    "                degree_score = max(degree_score, 2)\n",
    "                has_masters = 1\n",
    "        \n",
    "        # field analysis\n",
    "        stem_kw = ['computer', 'engineering', 'math', 'physics', 'science', 'data']\n",
    "        business_kw = ['business', 'mba', 'economics', 'finance', 'management']\n",
    "        is_stem = any(any(kw in f.lower() for kw in stem_kw) for f in fields)\n",
    "        is_business = any(any(kw in f.lower() for kw in business_kw) for f in fields)\n",
    "        \n",
    "        # QS ranking\n",
    "        best_qs = min(qs_ranks) if qs_ranks else 999\n",
    "        \n",
    "        features.append({\n",
    "            'edu_num_degrees': len(degrees),\n",
    "            'edu_highest_degree_score': degree_score,\n",
    "            'edu_best_qs_rank': best_qs if best_qs < 999 else np.nan,\n",
    "            'edu_is_top10_school': int(best_qs <= 10),\n",
    "            'edu_is_top50_school': int(best_qs <= 50),\n",
    "            'edu_is_top100_school': int(best_qs <= 100),\n",
    "            'edu_has_phd': has_phd,\n",
    "            'edu_has_mba': has_mba,\n",
    "            'edu_has_masters': has_masters,\n",
    "            'edu_has_advanced_degree': int(has_phd or has_mba or has_masters),\n",
    "            'edu_is_stem': int(is_stem),\n",
    "            'edu_is_business': int(is_business),\n",
    "            'edu_is_stem_and_business': int(is_stem and is_business),\n",
    "        })\n",
    "    \n",
    "    result = pd.DataFrame(features)\n",
    "    print(f\"  ‚úì Extracted {len(result.columns)} education features\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def extract_job_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Extract job-related features.\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    print(\"Extracting job features...\")\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        jobs_data = parse_json_column(row.get('jobs_json', '[]'))\n",
    "        \n",
    "        num_jobs = len(jobs_data)\n",
    "        roles = [j.get('role', '') for j in jobs_data]\n",
    "        industries = [j.get('industry', '') for j in jobs_data if j.get('industry')]\n",
    "        durations = [j.get('duration', '') for j in jobs_data]\n",
    "        company_sizes = [j.get('company_size', '') for j in jobs_data]\n",
    "        \n",
    "        # seniority\n",
    "        num_cxo = sum(1 for r in roles if any(kw in r.lower() for kw in ['ceo', 'cto', 'cfo', 'chief']))\n",
    "        num_founder = sum(1 for r in roles if any(kw in r.lower() for kw in ['founder', 'co-founder']))\n",
    "        num_vp = sum(1 for r in roles if any(kw in r.lower() for kw in ['vp', 'vice president']))\n",
    "        num_director = sum(1 for r in roles if any(kw in r.lower() for kw in ['director', 'head of']))\n",
    "        total_senior = num_cxo + num_founder + num_vp + num_director\n",
    "        \n",
    "        # role types\n",
    "        num_tech = sum(1 for r in roles if any(kw in r.lower() for kw in ['engineer', 'developer', 'scientist']))\n",
    "        num_product = sum(1 for r in roles if any(kw in r.lower() for kw in ['product', 'pm', 'ux']))\n",
    "        num_business = sum(1 for r in roles if any(kw in r.lower() for kw in ['sales', 'marketing', 'business']))\n",
    "        \n",
    "        # company size\n",
    "        big_co_kw = ['5001', '10001', '10000+', '1001-5000']\n",
    "        startup_kw = ['1-10', '11-50', '51-200']\n",
    "        has_big_co = any(any(kw in str(cs) for kw in big_co_kw) for cs in company_sizes if cs)\n",
    "        has_startup = any(any(kw in str(cs) for kw in startup_kw) for cs in company_sizes if cs)\n",
    "        \n",
    "        total_years = sum(parse_duration(d) for d in durations)\n",
    "        unique_industries = len(set(industries))\n",
    "        \n",
    "        features.append({\n",
    "            'job_num_prior_jobs': num_jobs,\n",
    "            'job_num_senior_roles': total_senior,\n",
    "            'job_num_cxo_roles': num_cxo,\n",
    "            'job_num_founder_roles': num_founder,\n",
    "            'job_num_tech_roles': num_tech,\n",
    "            'job_num_product_roles': num_product,\n",
    "            'job_num_business_roles': num_business,\n",
    "            'job_total_experience_years': total_years,\n",
    "            'job_num_industries': unique_industries,\n",
    "            'job_has_cxo_experience': int(num_cxo > 0),\n",
    "            'job_has_prior_founder_exp': int(num_founder > 0),\n",
    "            'job_has_big_company_exp': int(has_big_co),\n",
    "            'job_has_startup_exp': int(has_startup),\n",
    "            'job_is_technical': int(num_tech > 0),\n",
    "            'job_is_technical_senior': int(num_tech > 0 and total_senior > 0),\n",
    "            'job_is_repeat_founder': int(num_founder >= 2),\n",
    "            'job_big_company_then_startup': int(has_big_co and has_startup),\n",
    "        })\n",
    "    \n",
    "    result = pd.DataFrame(features)\n",
    "    print(f\"  ‚úì Extracted {len(result.columns)} job features\")\n",
    "    return result\n",
    "\n",
    "edu_features = extract_education_features(df)\n",
    "job_features = extract_job_features(df)\n",
    "X_baseline = pd.concat([edu_features, job_features], axis=1)\n",
    "\n",
    "print(X_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bb3394",
   "metadata": {},
   "source": [
    "### Removing Redundant Features \n",
    "\n",
    "This code is essentially feature quality analysis \n",
    "- Feature stats measure how useful a feature is for predicting a success\n",
    "    - Precision: of founders with this feature, how many are successful in %?\n",
    "    - Coverage: what % of founders have that feature?\n",
    "    - Lift: how much better than random base rate is this feature - precision/overall success? \n",
    "- Jaccard similarity measures how similar too binary features are\n",
    "    - this is intersection/union\n",
    "    - if two features are almost identical, one is redundant \n",
    "- Removal removes duplicates to reduce noise\n",
    "    - Ranks features by lift, keeps high-lift and removes too similar features\n",
    "    - Reduces overfitting, speeds up training and makes model more interpritable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0297f040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redundancy removal: 30 ‚Üí 17 features\n",
      "      edu_is_top10_school  edu_is_top50_school  job_is_technical_senior  \\\n",
      "0                       1                    1                        1   \n",
      "1                       1                    1                        0   \n",
      "2                       0                    0                        0   \n",
      "3                       1                    1                        0   \n",
      "4                       1                    1                        0   \n",
      "...                   ...                  ...                      ...   \n",
      "8995                    0                    0                        1   \n",
      "8996                    0                    0                        0   \n",
      "8997                    0                    1                        0   \n",
      "8998                    1                    1                        0   \n",
      "8999                    0                    0                        0   \n",
      "\n",
      "      edu_has_phd  job_big_company_then_startup  edu_is_stem  \\\n",
      "0               0                             0            1   \n",
      "1               0                             0            0   \n",
      "2               0                             1            0   \n",
      "3               1                             0            1   \n",
      "4               0                             0            0   \n",
      "...           ...                           ...          ...   \n",
      "8995            0                             1            1   \n",
      "8996            0                             0            0   \n",
      "8997            1                             1            1   \n",
      "8998            1                             1            0   \n",
      "8999            0                             1            1   \n",
      "\n",
      "      edu_highest_degree_score  job_is_repeat_founder  job_num_founder_roles  \\\n",
      "0                            0                      0                      0   \n",
      "1                            0                      0                      0   \n",
      "2                            0                      0                      0   \n",
      "3                            4                      0                      1   \n",
      "4                            0                      0                      0   \n",
      "...                        ...                    ...                    ...   \n",
      "8995                         0                      0                      0   \n",
      "8996                         0                      1                      7   \n",
      "8997                         4                      0                      0   \n",
      "8998                         4                      0                      0   \n",
      "8999                         0                      0                      0   \n",
      "\n",
      "      edu_has_mba  job_num_senior_roles  edu_has_masters  \\\n",
      "0               0                     2                0   \n",
      "1               0                     7                0   \n",
      "2               0                     0                0   \n",
      "3               0                     2                0   \n",
      "4               0                     2                0   \n",
      "...           ...                   ...              ...   \n",
      "8995            0                     1                0   \n",
      "8996            0                    11                0   \n",
      "8997            0                     3                0   \n",
      "8998            0                     3                1   \n",
      "8999            0                     6                0   \n",
      "\n",
      "      job_num_product_roles  edu_num_degrees  edu_is_stem_and_business  \\\n",
      "0                         0                1                         0   \n",
      "1                         2                0                         0   \n",
      "2                         0                0                         0   \n",
      "3                         0                2                         0   \n",
      "4                         0                1                         0   \n",
      "...                     ...              ...                       ...   \n",
      "8995                      0                1                         0   \n",
      "8996                      0                1                         0   \n",
      "8997                      0                4                         0   \n",
      "8998                      0                3                         0   \n",
      "8999                      0                1                         0   \n",
      "\n",
      "      edu_is_business  job_num_business_roles  \n",
      "0                   0                       0  \n",
      "1                   0                       2  \n",
      "2                   0                       0  \n",
      "3                   0                       0  \n",
      "4                   0                       0  \n",
      "...               ...                     ...  \n",
      "8995                0                       0  \n",
      "8996                0                       0  \n",
      "8997                0                       0  \n",
      "8998                0                       0  \n",
      "8999                0                       3  \n",
      "\n",
      "[9000 rows x 17 columns]\n",
      "[('edu_is_top100_school', 'edu_is_top50_school', 0.8078024337866857), ('job_num_tech_roles', 'job_is_technical_senior', 0.6573485811096993), ('job_is_technical', 'job_is_technical_senior', 0.6573485811096993), ('edu_has_advanced_degree', 'edu_highest_degree_score', 1.0), ('job_has_big_company_exp', 'job_big_company_then_startup', 0.6117021276595744), ('job_has_startup_exp', 'job_big_company_then_startup', 0.6467162080739104), ('job_has_prior_founder_exp', 'job_num_founder_roles', 1.0), ('job_num_cxo_roles', 'job_num_senior_roles', 0.7674528301886793), ('job_has_cxo_experience', 'job_num_senior_roles', 0.7674528301886793), ('job_num_industries', 'job_num_senior_roles', 0.6741714285714285), ('edu_best_qs_rank', 'job_num_senior_roles', 0.63917288914417), ('job_total_experience_years', 'job_num_senior_roles', 0.6887627695800227), ('job_num_prior_jobs', 'job_num_senior_roles', 0.7080828323313293)]\n"
     ]
    }
   ],
   "source": [
    "def compute_feature_stats(y: np.ndarray, feature_values: np.ndarray, \n",
    "                          threshold: Optional[float] = None) -> Dict:\n",
    "    \"\"\"Compute precision, coverage, and lift for a feature.\"\"\"\n",
    "    base_rate = y.mean()\n",
    "    \n",
    "    if threshold is not None:\n",
    "        applies = feature_values > threshold\n",
    "    else:\n",
    "        applies = feature_values.astype(bool)\n",
    "    \n",
    "    coverage = np.mean(applies)\n",
    "    n_applies = np.sum(applies)\n",
    "    \n",
    "    if n_applies > 0:\n",
    "        precision = y[applies].mean()\n",
    "        lift = precision / base_rate if base_rate > 0 else 0\n",
    "    else:\n",
    "        precision = 0.0\n",
    "        lift = 0.0\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"coverage\": coverage,\n",
    "        \"lift\": lift,\n",
    "        \"n_applies\": int(n_applies),\n",
    "        \"n_success_applies\": int(y[applies].sum()) if n_applies > 0 else 0,\n",
    "        \"base_rate\": base_rate\n",
    "    }\n",
    "\n",
    "def compute_jaccard_similarity(f1: np.ndarray, f2: np.ndarray) -> float:\n",
    "    \"\"\"Compute Jaccard similarity between two binary feature vectors.\"\"\"\n",
    "    f1_bool = f1.astype(bool)\n",
    "    f2_bool = f2.astype(bool)\n",
    "    intersection = np.sum(f1_bool & f2_bool)\n",
    "    union = np.sum(f1_bool | f2_bool)\n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "def remove_redundant_features(X: pd.DataFrame, y: pd.Series, \n",
    "                              threshold: float = 0.8) -> Tuple[pd.DataFrame, List]:\n",
    "    \"\"\"Remove features with Jaccard > threshold.\"\"\"\n",
    "    lifts = {}\n",
    "    for col in X.columns:\n",
    "        stats = compute_feature_stats(y.values, X[col].fillna(0).values)\n",
    "        lifts[col] = stats['lift']\n",
    "    \n",
    "    sorted_cols = sorted(X.columns, key=lambda c: lifts[c], reverse=True)\n",
    "    \n",
    "    kept_features = []\n",
    "    removed_features = []\n",
    "    \n",
    "    for col in sorted_cols:\n",
    "        is_redundant = False\n",
    "        for kept in kept_features:\n",
    "            sim = compute_jaccard_similarity(\n",
    "                X[col].fillna(0).values,\n",
    "                X[kept].fillna(0).values\n",
    "            )\n",
    "            if sim > threshold:\n",
    "                is_redundant = True\n",
    "                removed_features.append((col, kept, sim))\n",
    "                break\n",
    "        \n",
    "        if not is_redundant:\n",
    "            kept_features.append(col)\n",
    "    \n",
    "    print(f\"Redundancy removal: {len(X.columns)} ‚Üí {len(kept_features)} features\")\n",
    "    return X[kept_features], removed_features\n",
    "\n",
    "y = df['success']\n",
    "X_baseline_clean, removed_log = remove_redundant_features(X_baseline, y, threshold=0.6)\n",
    "\n",
    "print(X_baseline_clean)\n",
    "print(removed_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80cc90f",
   "metadata": {},
   "source": [
    "### Saving key information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc522968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\noutput_dir = Path(\"./outputs/experiment/processed\")\\n\\nX_baseline_clean.to_csv(output_dir / \\'baseline_features_COMBINED.csv\\', index=False)\\n\\npd.DataFrame({\\n    \\'founder_idx\\': range(len(y)),\\n    \\'success\\': y.values,\\n    \\'source\\': df[\\'source\\'].values  \\n}).to_csv(output_dir / \\'labels_COMBINED.csv\\', index=False)\\n\\nfounders_text = pd.DataFrame({\\n    \\'founder_idx\\': range(len(df)),\\n    \\'anonymised_prose\\': df[\\'anonymised_prose\\'],\\n    \\'source\\': df[\\'source\\']  \\n})\\nfounders_text.to_csv(output_dir / \\'founders_text_COMBINED.csv\\', index=False)\\n\\ndf.to_csv(Path(\"./data/raw\") / \\'vcbench_combined.csv\\', index=False)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "output_dir = Path(\"./outputs/experiment/processed\")\n",
    "\n",
    "X_baseline_clean.to_csv(output_dir / 'baseline_features_COMBINED.csv', index=False)\n",
    "\n",
    "pd.DataFrame({\n",
    "    'founder_idx': range(len(y)),\n",
    "    'success': y.values,\n",
    "    'source': df['source'].values  \n",
    "}).to_csv(output_dir / 'labels_COMBINED.csv', index=False)\n",
    "\n",
    "founders_text = pd.DataFrame({\n",
    "    'founder_idx': range(len(df)),\n",
    "    'anonymised_prose': df['anonymised_prose'],\n",
    "    'source': df['source']  \n",
    "})\n",
    "founders_text.to_csv(output_dir / 'founders_text_COMBINED.csv', index=False)\n",
    "\n",
    "df.to_csv(Path(\"./data/raw\") / 'vcbench_combined.csv', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b6fe10",
   "metadata": {},
   "source": [
    "# Metrics \n",
    "\n",
    "In traditional ML, we cant to classify everythign correctly so false positives and false negatives are equally as bad.\n",
    "\n",
    "As a VC, Vela wants to find the BEST founders to invest in with limited capital and time. This is reflected in the metrics used throughout this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910855d6",
   "metadata": {},
   "source": [
    "### Precision at K\n",
    "\n",
    "This is the most important metric and this:\n",
    "1. Ranks all foundres by their predicted success probability\n",
    "2. Takes the tok K (e.g top 100) highest scored founders\n",
    "3. Checks what % of the top k actually succeeded\n",
    "\n",
    "Lift refers to how much better your precision is that random success rate (which is 9% precision as this is how many successful foudners there are in the dataset)\n",
    "- For K = 100 founders, chosing 35 successful founders would be a 35% precision which is 3.5x lift better than the baseline of 9% successful founders in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac9b5847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision_at_k(y_true: np.ndarray, y_proba: np.ndarray, k: int) -> float:\n",
    "    \"\"\"Compute precision at top-K predictions.\"\"\"\n",
    "    top_k_idx = np.argsort(y_proba)[-k:]\n",
    "    return y_true[top_k_idx].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581c6072",
   "metadata": {},
   "source": [
    "### F Beta\n",
    "\n",
    "This is the foundaiton of the f0.5 score that is used by Vela. The idea is that, when you balance precision and recall preicsion is weighted more heavily when beta < 1.\n",
    "- F1 score (beta = 1): Equal weight to precision and recall\n",
    "- F0.5 score (beta = 0.5): Precision counts 2x more than recall\n",
    "- F2 score (beta = 2): Recall counts counts 2x more than precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7acec0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f_beta(precision: float, recall: float, beta: float = 0.5) -> float:\n",
    "    \"\"\"\n",
    "    Compute F-beta score.\n",
    "    \n",
    "    F0.5 weights precision MORE than recall (Vela's preferred metric).\n",
    "    From GPTree paper: \"we prioritize precision over recall\"\n",
    "    \"\"\"\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    beta_sq = beta ** 2\n",
    "    return (1 + beta_sq) * precision * recall / (beta_sq * precision + recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f2ca0e",
   "metadata": {},
   "source": [
    "### Metric Wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79516d1",
   "metadata": {},
   "source": [
    "These functions provide the utility to employ the above metrics\n",
    "- Compute precision recall builds a confusion matrix and calculates the f0.5\n",
    "    - TP: invest in founder who succeeded\n",
    "    - FP: invested in a founder who failed\n",
    "    - FN: passed on a founder who succeeded\n",
    "    - TN: passed on a founder who failed\n",
    "- Print vela metrics provides a comprehensive report during training comparing the model to benchmarks and providing the optimal threshold\n",
    "    - P@n is the precision if you invest in yuor top n picks and so on    \n",
    "    - P@x threshold is the precision at x confidence bar\n",
    "    - These results are compared to benchmarks from Vela papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8629ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision_recall_f05(y_true: np.ndarray, y_pred: np.ndarray) -> dict:\n",
    "    \"\"\"Compute precision, recall, and F0.5 score.\"\"\"\n",
    "    tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f05 = compute_f_beta(precision, recall, beta=0.5)\n",
    "    \n",
    "    return {'precision': precision, 'recall': recall, 'f05': f05,\n",
    "            'tp': int(tp), 'fp': int(fp), 'fn': int(fn)}\n",
    "\n",
    "def print_vela_metrics(y_true: np.ndarray, y_proba: np.ndarray, \n",
    "                       model_name: str = \"Model\"):\n",
    "    \"\"\"\n",
    "    Print metrics in Vela's preferred format.\n",
    "    \n",
    "    Reports: P@K, Precision, Recall, F0.5 (with min 10% recall constraint)\n",
    "    \"\"\"\n",
    "    base_rate = y_true.mean()\n",
    "    n_positive = int(y_true.sum())\n",
    "    \n",
    "    print(f\"\\n{'='*65}\")\n",
    "    print(f\"üìä {model_name} - VELA METRICS\")\n",
    "    print(f\"{'='*65}\")\n",
    "    print(f\"Base rate: {base_rate:.2%} ({n_positive} positive / {len(y_true)} total)\")\n",
    "    \n",
    "    # P@K metrics\n",
    "    print(f\"\\nüìà Precision @ K:\")\n",
    "    for k in [50, 100, 200, 500]:\n",
    "        if k <= len(y_true):\n",
    "            p_k = compute_precision_at_k(y_true, y_proba, k)\n",
    "            lift = p_k / base_rate if base_rate > 0 else 0\n",
    "            print(f\"   P@{k}: {p_k:.4f} ({lift:.2f}x lift)\")\n",
    "    \n",
    "    # Optimal threshold metrics (F0.5 with min 10% recall)\n",
    "    print(f\"\\nüéØ Optimal Threshold (min recall = 0%):\")\n",
    "    opt = find_optimal_threshold_f05(y_true, y_proba, min_recall=0.0)\n",
    "    print(f\"   Threshold: {opt['threshold']:.2f}\")\n",
    "    print(f\"   Precision: {opt['precision']:.4f} ({opt['precision']/base_rate:.2f}x lift)\")\n",
    "    print(f\"   Recall:    {opt['recall']:.4f} {'‚úì' if opt['recall'] >= 0.10 else '‚ö†Ô∏è < 10%'}\")\n",
    "    print(f\"   F0.5:      {opt['f05']:.4f}\")\n",
    "    print(f\"   (TP={opt['tp']}, FP={opt['fp']}, FN={opt['fn']})\")\n",
    "    \n",
    "    # Benchmark comparison\n",
    "    print(f\"\\nüìä Comparison to Vela Benchmarks:\")\n",
    "    print(f\"   {'Model':<20} {'Precision':<12} {'Recall':<10} {'F0.5':<10}\")\n",
    "    print(f\"   {'-'*52}\")\n",
    "    print(f\"   {'Your Model':<20} {opt['precision']:<12.3f} {opt['recall']:<10.3f} {opt['f05']:<10.3f}\")\n",
    "    print(f\"   {'RRF (paper)':<20} {'0.131':<12} {'0.101':<10} {'0.124':<10}\")\n",
    "    print(f\"   {'GPTree (paper)':<20} {'0.373':<12} {'0.271':<10} {'0.334':<10}\")\n",
    "    print(f\"   {'Tier-1 VCs':<20} {'0.056':<12} {'-':<10} {'-':<10}\")\n",
    "    \n",
    "    return opt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f095decc",
   "metadata": {},
   "source": [
    "### Threshold-based Metrics\n",
    "\n",
    "These functions were created but not used in training for a number of reasons:\n",
    "1. It is not natural for a VC to say 'invest above 65%'\n",
    "2. It is not flexible as there is a fixed threshold\n",
    "3. It is less generalisable to new data\n",
    "4. It does not preserve order and loses the relative ranking\n",
    "5. It overfits to validation\n",
    "6. 'Precision at 0.65' is far less interpritable than '37% hit rate in top 100'\n",
    "\n",
    "These functions threshold the probabiliy outputs to inflate precision\n",
    "\n",
    "- Find optimal threshold f0.5 finds the optimal 'confidence threshold' to make investment decisions\n",
    "    - when you train a ML model it outputs a probability for each founder which have to be converted into binary deicsions\n",
    "    - threshold for probility is optimsed on VALIDATION DATA using validation labels\n",
    "    - this maintains a minimum of 10% recall as want to catch some founders\n",
    "    - the threshold maximises f0.5 (precision weighted)\n",
    "    - this function tests 80 differnt thresholds and picks one based on the val data\n",
    "- Find threshold max precision can be used to maximise hit rate and ignore recall. This would be designed for a small fund that doesnt care about missing opportunities\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdd42ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_threshold_f05(y_true: np.ndarray, y_proba: np.ndarray,\n",
    "                                min_recall: float = 0.10) -> dict:\n",
    "    \"\"\"\n",
    "    Find threshold that maximizes F0.5 while maintaining minimum recall.\n",
    "    \n",
    "    Vela's guidance: \"Maintain recall at at least 10% and maximise precision\"\n",
    "    \"\"\"\n",
    "    best_f05 = 0\n",
    "    best_threshold = 0.5\n",
    "    best_metrics = None\n",
    "    \n",
    "    for threshold in np.arange(0.1, 0.9, 0.01):\n",
    "        y_pred = (y_proba >= threshold).astype(int)\n",
    "        metrics = compute_precision_recall_f05(y_true, y_pred)\n",
    "        \n",
    "        if metrics['recall'] >= min_recall and metrics['f05'] > best_f05:\n",
    "            best_f05 = metrics['f05']\n",
    "            best_threshold = threshold\n",
    "            best_metrics = metrics\n",
    "    \n",
    "    if best_metrics is None:\n",
    "        y_pred = (y_proba >= 0.5).astype(int)\n",
    "        best_metrics = compute_precision_recall_f05(y_true, y_pred)\n",
    "        best_threshold = 0.5\n",
    "    \n",
    "    best_metrics['threshold'] = best_threshold\n",
    "    return best_metrics\n",
    "\n",
    "def find_threshold_max_precision(y_true, y_proba, min_recall: float = 0.0):\n",
    "    \"\"\"\n",
    "    Choose the threshold that gives highest precision,\n",
    "    optionally with a minimum recall constraint.\n",
    "    \"\"\"\n",
    "    best_prec = 0.0\n",
    "    best_thr = 0.5\n",
    "    best_metrics = None\n",
    "\n",
    "    for thr in np.arange(0.1, 0.95, 0.01):\n",
    "        y_pred = (y_proba >= thr).astype(int)\n",
    "\n",
    "        tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "        fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "        fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "\n",
    "        prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        rec  = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "\n",
    "        if rec >= min_recall and prec > best_prec:\n",
    "            best_prec = prec\n",
    "            best_thr = thr\n",
    "            best_metrics = {\n",
    "                \"precision\": prec,\n",
    "                \"recall\": rec,\n",
    "                \"tp\": int(tp),\n",
    "                \"fp\": int(fp),\n",
    "                \"fn\": int(fn),\n",
    "                \"threshold\": thr,\n",
    "            }\n",
    "\n",
    "    if best_metrics is None:  # fallback\n",
    "        thr = 0.5\n",
    "        y_pred = (y_proba >= thr).astype(int)\n",
    "        m = compute_precision_recall_f05(y_true, y_pred)\n",
    "        m[\"threshold\"] = thr\n",
    "        return m\n",
    "\n",
    "    return best_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b772f69f",
   "metadata": {},
   "source": [
    "# Graph Building\n",
    "\n",
    "In this section we are building the heterogenous graph structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7496825e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b91ca00",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18755aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6233f3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cd795b5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da06403c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vela_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
